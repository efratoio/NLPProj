%!TEX root = main.tex
\section{Model and Design}\label{sec:model}

\subsection{Model}
In this section we detail our problem model and the necessary background 
for our solution.

The problem we aim to solve is related to the Document Classification task 
\cite{attention,Slonim:2002:UDC:564376.564401,DBLP:journals/tkde/IsaLKR08} 
and tries to infer the direction the dialog is headed. 
In our model, we consider a dialog between two sides (a chatbot and a customer, two friends, etc.). 
A dialog can be modeled as a sequence of turns, 
where each turn is associated with a timestamp and a speaker, and can consist of several sentences. 
Therefore, we denote the set of all sequences of 
such turns by $\mathcal{T}$ and define the concepts of {\em sequence prefix} and {\em full dialog}. 

\begin{definition}
For $seq_1, seq_2 \in \mathcal{T}$, we say that $seq_1$ is the 
prefix of $seq_2$ and denote by $seq_1 = pr(seq_2)$, if 
$seq_1 = (t_1, \ldots, t_j)$, $seq_1 = (t_1, \ldots, t_j, \ldots, t_n)$, i.e., $seq_1$ contains the first 
turns in $seq_2$. 

We say that $seq \in \mathcal{T}$ is a full dialog if $\;\forall seq' \in \mathcal{T}. seq \neq pr(seq')\; $ 
\end{definition}

A {\em full dialog} is then a sequence $seq \in \mathcal{T}$ that is not a prefix 
of any other $seq' \in \mathcal{T}$. 
We then define an instance of {\em dialog-end}. 

\begin{definition}\label{def:target}
Given an integer $k$, an instance of dialog-end is a set of sequences of turns $T=\{seq_1, \ldots, seq_n\} \subseteq \mathcal{T}$ such that 
(1) each turn $t_i$ is associated with a timestamp and a speaker, (2) for every sequence $seq_i\in T$, there exists a full dialog $seq_j\in \mathcal{T}$ such that $seq_i = pr(seq_j)$, and $|seq_i| = k$ for all $1\leq i \leq n$.
\end{definition}

\begin{example}\label{ex:seq}
Here is an example of a sequence of turns from a chat where $k=6$:
\begin{table}[!htb]
\centering
\begin{tabular}{| c | c | l |}
\hline Turn & Speaker & Text \\
\hline 1 & user & \begin{tabular}[x]{@{}l@{}}Hi. I need to book a vacation to Long Beach between August 25 \\and September 3. Departure is from Paris\end{tabular} \\
\hline 2 & bot & Would you like to depart Paris on September 6th? \\
\hline 3 & user & Preferably by the 3rd. Is there anything available? \\
\hline 4 & bot & \begin{tabular}[x]{@{}l@{}}Sorry, looks like there is nothing available from Paris to Long Beach on \\September 3rd.\end{tabular} \\
\hline 5 & user & \begin{tabular}[x]{@{}l@{}}I'm not quite sure I understand, is there anything available leaving \\Long Beach to go to Paris between August 25 and September 3rd?\end{tabular} \\
\hline 6 & bot & Would you like to depart Paris on September 6th? \\
\hline
\end{tabular}
%\vspace{-2mm}
% \caption{Notations}\label{notations}
% \vspace{-3mm}
\end{table}
\end{example}

The full dialogs we consider are targeted at a specific purpose 
(whether it be convincing the customer to purchase a product, helping a friend accomplish a task, etc.), 
and thus can be defined by their outcome, which 
is either success of failure (the customer buying the product, the friend accomplished the task, etc.). 
This concept can be modeled as another feature associated with the full dialog, where 1 means 
that the full dialog is successful and 0 means that it is not. 

\begin{example}
Reconsider the sequence in Example \ref{ex:seq}.  
If by the end of the full dialog, whose prefix is the mentioned sequence, 
the user books a vacation, the dialog is considered successful.
\end{example}
% Thus, we define the {\em dialog-end problem} as a target function, intuitively predicting the outcome of the chat from its prefix.

% \begin{definition}\label{def:target}
% Given an integer $k$ and a set of sequences of turns $T=\{seq_1, \ldots, seq_n\} \subseteq \mathcal{T}$,
% where each turn $t_i$ is associated with a timestamp and a speaker, for every sequence $seq_i\in T$, there exists a full dialog $seq_j\in \mathcal{T}$ such that $seq_i = pr(seq_j)$, and $|seq_i| = k$ the solution to the dialog-end 
% problem is a function $f:T \to \{0,1\}$ where for each sequence $seq_i$, $f(seq_i) = 1$ iff the $seq_j$ is successful. 
% \end{definition}

Our task is then a binary classification 
problem of finding a function that predicts the outcome 
of a full dialog $seq_j$ from its prefix $seq_i = pr(seq_j)$. 

Note that for every choice of $k$ we get a different 
version of the problem and where a larger $k$ leads 
to a supposedly easier problem, since each sequence contains 
more information from the chat, until the elements of $T$ 
are the entire chat. The case where the entire chats are 
given can be interpreted as challenge in the Dialog Act \cite{cs-CL-0006023,DBLP:conf/icassp/JiB05,DBLP:conf/coling/WermterL96}
field and can be solved using similar approaches, since we 
can tag all actions and search for the action signaling the task's completion. 
In our setting, however, we assume that $k$ is smaller than the dialog 
length, thus presenting a different challenge, requiring a somewhat different approach. 

\subsection{Features}
We use two types of features, designed to capture
different aspects of the problem. We use neural 
language model features to leverage corpus
level word distributions and sentence understandings, 
specifically longer term
sequence probabilities. In addition, we use the meta-data of the chat in order to extract characteristics features of the chat 
to help capture other aspects.

\paragraph*{Language Model Features}
\amir{Efrat - Complete}
A basic approach in this model of dialog is 
using the semantic feature expressed in the text. 
We use the GloVe \cite{glove} encoder to translate the words 
into vectors and then use the network to extract sentences and 
dialog vectors (see Section \ref{sec:network}). 



\paragraph*{Auxiliary Semantic Features}\label{sec:semantic}
Including additional features 
extracted from the meta-data of the chat can further enrich the our model. 

We add the following semantic features 
to describe the general nature 
of the interaction between the two sides 
in the sequence. All features here 
are computed from the given meta-data of the sequence and 
are part of the final representation of the data as it goes into the 
third level of the network (see Section \ref{sec:network}). 

\begin{enumerate}
\item {\bf Time between turns: } the time between 
turns of the two sides, i.e. how long does it take to respond or ask a follow-up 
question after a given sentence on average. 
If responses are fast, it can imply that one side is dissatisfied 
from the other and does not have to think of her replies or whether 
she should agree with the other side\label{itm:between}

\item {\bf Total time of the chat: } the total time of the interaction \label{itm:total}

\item {\bf Average turn length for each speaker: } since there are two sides to the dialog, 
we take the average of length of the turn for each of the two sides. 
A turn that contains more words means a more elaborate description, which indicates 
a good first impression\label{itm:sent}


\item {\bf Monetary Mentions: } if the topic of budget or money is mentioned in the dialog, 
Intuitively, this feature indicates a progress in the booking process\label{itm:budget}

% \item {\bf Dominant speaker: } Who is the speaker who is associated with the majority of sentences in the sequence 
\end{enumerate} 

\subsection{Ontology}
\amir{Slava - talk about semantic difference between sentences}