{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def build_label_dict():\n",
    "    d = {}\n",
    "    \n",
    "    label_path = r\"../Frames-dataset/labels.txt\"\n",
    "    label_file = open(label_path, encoding='utf-8')\n",
    "    for line in label_file:\n",
    "        k, v = line.split(\"\\t\")\n",
    "        d[k] = int(v.strip())\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vectors from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# NOT IN USE RIGHT NOW\n",
    "def compute_sum_ts(prev_ts, cur_ts, sum_ts):\n",
    "    if cur_ts != 0:\n",
    "        sum_ts += cur_ts - prev_ts\n",
    "    return sum_ts\n",
    "\n",
    "\n",
    "def update_ts(chat, i, cur_ts):\n",
    "    prev_ts = cur_ts\n",
    "    cur_ts = chat['turns'][i]['timestamp']\n",
    "    return prev_ts, cur_ts\n",
    "\n",
    "def update_sent_len(chat, i, avg_len_speaker, avg_len_wizard):\n",
    "    if chat['turns'][i]['author'] == 'user':\n",
    "        avg_len_speaker += len(chat['turns'][i]['text'].split())\n",
    "    else:\n",
    "        avg_len_wizard += len(chat['turns'][i]['text'].split())\n",
    "    return avg_len_speaker, avg_len_wizard\n",
    "\n",
    "def gen_vector(k, chat):\n",
    "    tss = []\n",
    "    is_budget = 0\n",
    "    avg_len_user, avg_len_wizard = 0, 0 # aveage sent len of user and wizard\n",
    "    cur_ts = first_ts = chat['turns'][0]['timestamp']\n",
    "    prev_ts = 0\n",
    "    for i in range( k ):\n",
    "        # sent len feature\n",
    "        avg_len_user, avg_len_wizard = update_sent_len(chat, i, avg_len_user, avg_len_wizard) # update avg sent len\n",
    "        # timelapse feature\n",
    "        prev_ts, cur_ts = update_ts(chat, i, cur_ts)\n",
    "        if i > 0:\n",
    "            tss.append( cur_ts - prev_ts )# start with the diff from first to second frame\n",
    "        # budget feature\n",
    "        for arg in chat['turns'][i]['labels']['acts']:\n",
    "            for inner_dict in arg['args']:\n",
    "                if  inner_dict['key'] == 'budget':\n",
    "                    is_budget = 1 # talking about the budget\n",
    "    \n",
    "    # total time feature\n",
    "    total_time = (prev_ts - first_ts) / pow(10,6) # chat total time normalized\n",
    "    avg_len_user = avg_len_user * 2 / (100 * k)\n",
    "    avg_len_wizard = avg_len_wizard * 2 / (100 * k)\n",
    "    tss = [x / pow(10,6) for x in tss]\n",
    "    tss.extend([total_time, avg_len_user, avg_len_wizard, is_budget]) # list of all features\n",
    "    chat_vec = np.array(tss) # gen feature vector\n",
    "    return chat_vec\n",
    "\n",
    "def gen_data(d, k):\n",
    "    chat_path = r\"../Frames-dataset/chats\"\n",
    "    chat_features = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(chat_path):\n",
    "        chat_file = open(os.path.join(chat_path, filename), encoding='utf-8')\n",
    "        chat = json.load(chat_file)\n",
    "        if len(chat['turns']) >= k: # skip really short chats\n",
    "                labels.append(d[filename])\n",
    "                chat_features.append( gen_vector(k, chat) )\n",
    "    return np.array(chat_features), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_334 (Dense)            (None, 12)                96        \n",
      "_________________________________________________________________\n",
      "dense_335 (Dense)            (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_336 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 209\n",
      "Trainable params: 209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "acc: 64.63%\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, merge, Embedding, Activation\n",
    "from keras.models import Sequential\n",
    "TRAIN_SIZE = 1000\n",
    "K = 4 # number of sentences from start of chat\n",
    "INPUT_DIM = K + 3\n",
    "\n",
    "# Generate data\n",
    "d = build_label_dict()\n",
    "X, Y = gen_data(d, K)\n",
    "\n",
    "# Divide into training and test data\n",
    "x_train, y_train = X[:TRAIN_SIZE], Y[:TRAIN_SIZE]\n",
    "x_test, y_test = X[TRAIN_SIZE:], Y[TRAIN_SIZE:]\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=INPUT_DIM, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())\n",
    "\n",
    "# Compile and fit\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Test the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
