%!TEX root = main.tex
\section{Introduction}
Dialog understanding has been the subject of 
extensive research \cite{BohusR03,BordesW16,GhazvininejadBC17,ShawarA03,DBLP:conf/icassp/JiB05,DBLP:conf/coling/WermterL96}. These works explore 
different aspects of dialogs, from winning an argument \cite{TanNDL16} 
to automatically recognize the emotions conveyed in a conversation at each segment \cite{AyadiKK11}. 
Our project aims to employ NLP and machine learning techniques to 
predict the {\em bottom-line} of a conversation, based on segments 
of it. Such a system can be highly useful in the context of automatic 
chatbots. Consider, for example, a chat with a potential customer where 
from a certain point in the dialog, the system can asses the probability of a purchase 
or what strategy it should employ in order to get there. 
Customer service teams can also benefit from the system as they can decide 
from whether a customer is calling to terminate the contract with the company 
or just to get a discount.

\section{Solution Details}
To predict the bottom-line, our solution will include several stages. 
First, we will identify the topic of the conversation and named entities 
appearing in it. Second, we will segment the conversation, 
and cluster the different segments to identify types of 
``Conversational building blocks'' and learn probabilities 
of transferring from one type of segment to another. 
On top of the segments classification, we will extract features of 
conversation (e.g., dominance of one of the parties, 
the volume of text in the replies, usage of positive/negative words, 
time lapses between responses). 
We will use these features as input to MEMM/RNN to predict the 
most probable continuation of the conversation 

One of the challanges will be to identify the main topic of the whole conversation, and for each
part of it. To address this issue our solution will use external knowledge base, for the relevant
domain (i.e. if we will use e-commerce chatbots conversations - the knowledge base will be a
catalog of products and their properties. For predicting outcome of geopolitical conversations we
will use knowledge bases as YAGO and DBPedia). Using of the knowledge base will allow us to
have better semantic understanding of the dialog, both while training the model and for testing. 
Using knowledge base we can find similarities between different conversations (i.e. consider a chat about travelling suggestions, one about New York (on training step) and the second one about Tokyo (testing). Understand that both New York and Tokyo are cities will allow us to reuse the information about dialogs). Moreover, clustering dioalogs based on semantic similarity can be a boost for a better training.

\section{Data}
We focus on datasets regarding {\em Dialog Act} (or DA) where all the relevant corpora is tagged with Dialog Act tags. 
This is a tag given to each utterance in the conversation and represents the act that was done by it. 
For example, agreement, question, answer, etc.

% There are several standards of DA (e.g. DAMSL, DIT++). \amir{how is this related?}
\begin{itemize}
	\item {\bf The NPS Chat Corpus:} The NPS Chat Corpus, Release 1.0 consists of 10,567 posts 
	out of approximately 500,000 posts gathered from various online chat services.
	Each reply is tagged with POS for every word and also a tag that is given to that reply - Accept, Bye, Clarify, Continuer, Emotion, Emphasis, Greet, No Answer, Other, Reject, Statement, System, Wh-Question, Yes Answer, Yes/No Question.
	\item {\bf AMI corpus:} The AMI Meeting Corpus is a collection of recordings of meetings based on a scenario. 
	The subject of this scenario is the design of a remote control device in a virtual company.
	The correspondence is annotated with dialog acts, in addition to segments of the conversation that are labeled with topics, 
	subtopics, and functional labels (these are 4 types of labels: Opening, Closing, Agenda/Equipment and Chitchat).
	\item {\bf The Dialog Bank:} Contains four dialog corpora in English and four in Dutch. 
	All corpora is annotated with ISO 24617-2, DIT++ and DAMSL annotations (these are standard for DA labeling).
\end{itemize}

\section{Related Work}
Dialog analysis studies first emerged in in the context of linguistics.
John L. Austin introduced the concept of "Speech Act". He observed that in the act of speaking 
the meaning of the utterance cannot be determined solely on the facts stated, 
but there is a notion of action that the speaker perform while uttering that phrase.

The speech act notion was used later on, in order to learn and understand the structure of a conversation, similar to the way parts of speech are used to understand the structure of a sentence. \cite{cs-CL-0006023} describes algorithms to label conversations with Dialog Acts, and used it on a large corpora of speech (e.g. switchboard corpus of human-human conversational telephone speech). 
Dialogs consist of turns each turn consists of utterances
The discourse structure annotation Dialog Act Markup in Several Layers – DAMSL
These DA labels used to build a discourse grammar - statistical model for DA sequences.
The probabilities for this grammar are based on the words transcribed, words recognized acoustics, 
and prosodic features – acoustics features like pitch, duration, etc.

One on the shortcomings of the Markovian assumption (Not considering global objectives) is that it cannot capture conversational games i.e. the notion that sometimes a new thread is opened in a conversation and then closed. 
\cite{Geertzen} suggests employing CFG grammar to handle this issue.
Research on involving graphical methods or recurrent neural networks to derive DA (e.g. \cite{DBLP:conf/icassp/JiB05,DBLP:conf/coling/WermterL96}) also exist. These works concluded that factored language models work better then n-gram switching overall.